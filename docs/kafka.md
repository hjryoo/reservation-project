1. Apache Kafka란?

Apache Kafka는 대규모 실시간 데이터 스트리밍 처리를 위한 분산 메시징 시스템으로, LinkedIn에서 처음 개발되어 현재는 높은 처리량과 안정적인 가용성을 바탕으로 백엔드 아키텍처의 핵심 인프라로 자리매김하고 있다.

왜 Kafka를 사용하는가? (기존 HTTP 통신과 비교)

기존의 동기식 HTTP 요청-응답 방식에서는 시스템 간 결합도가 높아, 예를 들어 주문 서비스가 데이터 플랫폼으로 정보를 전송할 때 데이터 플랫폼 서버가 장애를 일으키면 주문 서비스 역시 영향을 받는다. 이로 인해 복잡한 재시도 로직이 필요하거나 시스템 전반에 불안정성이 커진다.

Kafka 도입 시의 핵심 이점은 다음과 같다.

- 결합도 감소: Producer(송신자)는 Consumer(수신자)의 처리 상태에 상관없이 메시지만 전송하면 된다. 즉, 메시지를 던진 뒤 결과를 기다릴 필요 없이 업무를 처리할 수 있다.
- 대용량 트래픽 버퍼링: 트래픽이 한꺼번에 몰릴 경우 Kafka가 메시지를 디스크에 저장해두기 때문에, Consumer가 자신의 처리 능력에 맞춰 천천히 데이터를 가져올 수 있어 시스템에 과부하가 생기지 않는다.
- 높은 처리량: 데이터를 일정 단위로 모아 일괄(Batch) 방식으로 전송하고 처리함으로써, 시스템 전체의 효율성이 크게 향상된다.

2. 핵심 아키텍처 및 주요 용어

Kafka 시스템을 이해하기 위해 아래 용어를 알아두면 좋다.

2.1. Topic과 Partition

- Topic은 메시지를 분류하는 기준으로, 폴더와 유사한 개념이다. 예를 들어 reservation-completed, payment-success등의 이름으로 관리할 수 있다.
- Partition은 하나의 Topic을 여러 개의 부분으로 나누어 데이터를 분산 저장하는 단위다.
    - 파티션 단위로 병렬 처리가 이루어지므로, 파티션이 3개라면 최대 3개의 컨슈머가 동시에 데이터를 처리할 수 있다.
    - 순서 보장: Kafka는 전체 메시지의 전반적인 순서는 보장하지 않지만, 각 파티션 안에서는 메시지 순서가 보장된다. 따라서 결제 이력 등 순서가 중요한 데이터의 경우 동일한 Key를 사용해 같은 파티션에 저장해야 데이터의 순서가 유지된다.

2.2. Broker와 Zookeeper

- Broker는 Kafka 서버 한 대를 의미한다. Producer로부터 수신한 메시지를 디스크에 저장 후, Consumer에게 전달하는 역할을 한다. 일반적으로 안정성을 위해 3대 이상의 Broker로 클러스터를 구성한다.
- Zookeeper는 여러 Broker의 상태를 관리하고, 리더 선출 등 메타데이터를 조정하는 코디네이터 역할을 한다. 최근에는 KRaft 모드가 도입되고 있으나, 실습 환경에서는 주로 Zookeeper를 사용한다.

2.3. Producer와 Consumer

- Producer는 이벤트를 생성해 Kafka의 특정 Topic으로 전송하는 애플리케이션이다. (예: 우리의 ReservationService)
- Consumer는 Topic을 구독하고 메시지를 가져와 처리하는 애플리케이션이다. (예: DataPlatformListener)
    - 특징: Consumer가 Broker에게 직접 데이터를 요청하여 자신이 처리 가능한 만큼만 받아온다(Pull 방식). 이 구조 덕분에 Consumer의 처리량에 맞춰 시스템이 유연하게 동작한다.

2.4. Consumer Group

- Consumer Group은 하나의 Topic을 여러 컨슈머 인스턴스가 나누어서 처리할 수 있도록 구성된 그룹이다.
    - 확장성: 메시지의 양이 증가할 때 Consumer 인스턴스를 늘리면 각 파티션을 여러 인스턴스가 병렬로 분배 처리할 수 있기 때문에 확장성이 매우 뛰어나다.
    - 리밸런싱: 컨슈머 인스턴스 중 하나가 장애로 빠지면 Kafka가 자동으로 남은 인스턴스에게 파티션 소유권을 재분배한다.

2.5. 복제(Replication)

고가용성을 보장하기 위해 각 파티션은 여러 브로커에 복제되어 저장된다.

- 리더: 파티션의 원본으로, 모든 읽기 및 쓰기 작업이 리더를 통해 처리된다.
- 팔로워: 리더의 데이터를 그대로 복제해 두는 백업 역할을 한다. 만약 리더 브로커에 장애가 발생하면, 팔로워 중 한 대가 자동으로 리더로 승격된다.

3. 프로젝트 적용 시나리오

현재 예약 서비스에서 데이터 플랫폼으로 전송하는 로직에 Kafka를 도입한다.

- 변경 전: 예약이 완료되면 RestTemplate을 이용해 외부 API를 호출한다. 외부 서버에 장애가 발생하면 데이터 유실 위험이 있다.
- 변경 후:
    - 예약 서비스(Producer)는 예약 완료 이벤트를 ‘concert-reservation’ 토픽에 발행한 후, 즉시 응답을 반환한다. 이를 통해 응답 속도가 빨라진다.
    - 데이터 플랫폼(Consumer)은 ‘concert-reservation’ 토픽을 구독하고 있다가 메시지가 도착하면, 해당 데이터를 비동기적으로 수신하여 적재한다. 이로써 장애에 대한 내성을 확보할 수 있다.